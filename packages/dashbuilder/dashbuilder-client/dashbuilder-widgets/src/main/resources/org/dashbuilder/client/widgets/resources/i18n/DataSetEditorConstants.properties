newDataSet=New {0} Data Set
error=An error has occurred
type=Type
message=Message
cause=Cause
ok=Ok
loading=Loading
selectType=Select the provider type
bean=Bean
csv=CSV
sql=SQL
prometheus=Prometheus
kafka=Kafka
bean_description=Bean provider allows to consume data generated by a Java class
csv_description=CSV provider allows to consume data present in a CSV file
sql_description=SQL provider allows to consume data present in an SQL storage system
prometheus_description=Prometheus provider allows you to consume data from a Prometheus Query
kafka_description=Kafka provider allows to grab metrics from Kafka broker, consumer or producer
next=Next
next_description=Go to provider configuration edition
updateTest_description=Test your data provider configuration updated parameters by performing a data lookup to the remote system. Attention: the table on preview tab will be updated and you will lose your current columns and filter configurations, if any.
test=Test
test_description=Test your data provider configuration parameters by performing a data lookup to the remote system. The result of the lookup is displayed on the next screen.
save=Save
save_description=Save your data set and register it to make it available
back=Back
back_description=Go back to the type selection screen
performance=Performance
backendCache=Backend Cache
clientCache=Client Cache
none=None
refreshOnStaleData=Refresh on stale data
refreshEvery=Data refresh every
bytes=Bytes
rows=Rows
attributeId=Id
attributeColumnType=Column data type
attributeColumnType_description=The data type for the data set column
labelColumnType_description=Label columns support group operations. A group operation on a Label column generates one row per distinct value. For instance, a pie chart will display as many slices as labels available.
textColumnType_description=Text columns do not support group operations  (unlike Label columns). So they are usually displayed as raw data in non-categorized visualizations like table reports.
numberColumnType_description=Number columns do not support group operations.  However, when the dataset is grouped by a label or date column, different aggregation functions can be applied over the Number column: sum, average, min, max, etc.
dateColumnType_description=Date columns support group operations. Different time intervals are supported: second, hour, day, week, month, etc.
attributeUUID=UUID
attributeUUID_description=Data set''s unique identifier. Useful for referencing the data set
attributeName=Name
attributeName_description=Data set''s name. A descriptive string that describes the data set
attributeMaxBytes=Max bytes
attributeMaxBytes_description=If client cache is enabled, specify the maximum size (in bytes) allows for pushing data set into client. If data set size is greater than this value, it is not pushed into client
attributeMaxRows=Max rows
attributeMaxRows_description=If backend cache is enabled, specify the maximum size (in rows) allowed for caching data set in memory. If data set size is greater than this value, it is not cached
attributeRefreshInterval=Interval
attributeRefreshInterval_description=If data set refresh is enabled, specify the interval for refreshing it. On each refresh, a look up to the external storage system is done
on=ON
off=OFF
sql_datasource=Data Source
sql_datasource_description=The connection to the database. It is always provided by the underlying container.
sql_datasource_placeHolder=java:jboss/datasources/ExampleDS
sql_datasource_selectHint=- Select data source -
sql_schema=Schema
sql_schema_description=The database schema, if necessary. Can be empty
sql_schema_placeHolder=MySchema01
sql_table=Table
sql_table_description=The database table to query
sql_table_placeHolder=MyTable
sql_source=Source
sql_source_description=Either the name of an existing database table or a complete SQL sentence
sql_query=Query
sql_query_description=An ANSI SQL query for fetching the data set
sql_query_placeHolder=select * from MyTable
csv_filePath=File path
csv_filePath_description=The local file system path where the CSV file is located
csv_URL=File URL
csv_URL_description=The URL to the CSV contents, f.i: http://myhost.com/myreports.csv
csv_URL_placeholder=file:///home/dashbuilder/myReports.csv
csv_useFilePath=Switch to file selector mode
csv_useFileURL=Switch to remote URL mode
csv_sepChar= Separator char
csv_sepChar_description= The character used to separate values
csv_sepChar_placeholder= Separator char (;)
csv_quoteChar=Quote char
csv_quoteChar_description=The character used for quotes
csv_quoteChar_placeholder=Quote char (\\)
csv_escapeChar=Escape char
csv_escapeChar_description=The character used for escaping values
csv_escapeChar_placeholder=Escape char (\\)
csv_datePattern=Date pattern
csv_datePattern_description=The date pattern for consuming date column values present in the CSV file
csv_datePattern_placeholder=Date pattern  (MM-dd-yyyy)
csv_numberPattern=Number pattern
csv_numberPattern_description=The number pattern for consuming number column values present in the CSV file
csv_numberPattern_placeholder=Number pattern (#,###.##)
el_server_url=Transport client
el_server_url_description=The transport client address for consuming services from an Elastic Search node. f.i: localhost:9300
el_server_url_placeholder=localhost:9300
el_cluster_name=Cluster name
el_cluster_name_description=The name of the cluster. Can be empty
el_cluster_name_placeholder=my_cluster
el_index=Index
el_index_description=The index to use
el_index_placeholder=my_index
el_type=Document type
el_type_description=The document type to query for the given index. Can contain multiple values comma separated. If empty, all document types the given current index will be consumed
el_type_placeholder=my_type
bean_generator_class=Generator class
bean_generator_class_description=The full qualified class name of the Java class that generates the data set. f.i: org.example.MyDataSetGenerator
bean_generator_class_placeholder=org.example.MyDataSetGenerator
bean_generator_params=Generator parameters
bean_generator_params_description=A list of value pair parameters to use as generator''s class arguments
tab_configguration=Configuration
tab_preview=Preview
tab_advancedConfiguration=Advanced
filter=Filter
dataColumns=Data columns
dataSetMustHaveAtLeastOneColumn=Data Set must have at least one column
columnIsUsedInFilter=The column is used in the filter
label=Label
text=Text
number=Number
date=Date
showColumnsAndFilter=Show columns and filter panel
hideColumnsAndFilter=Hide columns and filter panel
defNotFound=Data Set definition not found or this data set has no definition
prometheus_server_url=Server Url
prometheus_server_url_description=Prometheus server URL f.i: http://localhost:9090/
prometheus_server_url_placeholder=http://localhost:9090
prometheus_query=Query
prometheus_query_description=The query used to retrieve data for this dataset
prometheus_query_placeholder=time()
kafka_host=Host
kafka_host_description=Host where Kafka Broker/Consumer/Producer is running
kafka_host_placeholder=127.0.0.1
kafka_port=Port
kafka_port_description=JMX Port according to Kafka JMX
kafka_port_placeholder=9999
kafka_target=Target
kafka_target_description=The target for metric collection. The output changes according to the selected target.
kafka_filter=Filter
kafka_filter_description=Filter the metrics from data set result. Filter works on domain, type and name columns.
kafka_clientId=Client ID
kafka_clientId_description=The Client ID. Required for Consumer/Producer metrics.
kafka_nodeId=Node ID
kafka_nodeId_description=Node ID that can be used with Consumer/Producer metrics
kafka_topic=Topic
kafka_topic_description=Topic to monitor. Should be used with Consumer/Producer metrics
kafka_partition=Partition
kafka_partition_description=Partition to monitor. It should be used specifically with Consumer and topic configuration.

remoteDataSetEditor=Execution Server
remoteDataSetEditorDescription=Execution Server provider allows to consume data via custom queries feature of the Execution Server
remoteQueryTarget=Remote query target
remoteQueryTargetHint=Select query target
remoteServerTemplateHint=Select server configuration
remoteServerTemplate=Remote Server Template
remoteServerTemplateDescription=Server configuration
remoteDatasourceDescription=Data source
remoteQueryTargetDescription=Query target that will be executed on Kie Server
remoteSourceDescription=The source
remoteQueryPlaceHolder=select * from ProcessInstanceLog
remoteSqlSource=Source
remoteSqlDatasource=Datasource used to run queries
